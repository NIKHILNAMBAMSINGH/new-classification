{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BQB56y0iS2Ag"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = Sequential()\n",
        "\n",
        "# Convolutional layer 1\n",
        "model5.add(Conv2D(64,(7,7), input_shape=(240, 240, 1), padding='same', activation='relu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Convolutional layer 2\n",
        "model5.add(Conv2D(128,(7,7), padding='same', activation='relu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Convolutional layer 3\n",
        "model5.add(Conv2D(128,(7,7), padding='same', activation='relu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Convolutional layer 4\n",
        "model5.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        " # Convolutional layer 5\n",
        "model5.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Convolutional layer 6\n",
        "model5.add(Conv2D(512,(7,7), padding='same', activation='relu'))\n",
        "model5.add(BatchNormalization())\n",
        "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model5.add(Flatten())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model5.add(Dense(units= 1024, activation='relu'))\n",
        "model5.add(Dropout(0.25))\n",
        "model5.add(Dense(units=512, activation='relu'))\n",
        "model5.add(Dropout(0.25))\n",
        "model5.add(Dense(units=4, activation='softmax'))"
      ],
      "metadata": {
        "id": "f_zzEXq3T51h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rotation_range=10,\n",
        "                             height_shift_range=0.2,\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "train_data = datagen.flow_from_directory('/content/drive/MyDrive/brain dataset/Training/',\n",
        "                                         target_size=(240, 240),\n",
        "                                         batch_size=32,\n",
        "                                         class_mode='categorical',color_mode='grayscale')\n",
        "\n",
        "valid_data = datagen.flow_from_directory('/content/drive/MyDrive/brain dataset/Testing/',\n",
        "                                         target_size=(240, 240),\n",
        "                                         batch_size=32,\n",
        "                                         class_mode='categorical', color_mode='grayscale')\n",
        "\n",
        "#test set\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "test_data = datagen.flow_from_directory('/content/drive/MyDrive/brain dataset/Testing/',\n",
        "                                         target_size=(240, 240),\n",
        "                                        class_mode='categorical',shuffle=False, color_mode='grayscale')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyAsaUZ3T-UH",
        "outputId": "6d368cee-f20d-4272-aae3-74cb18da0513"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5712 images belonging to 4 classes.\n",
            "Found 1311 images belonging to 4 classes.\n",
            "Found 1311 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(optimizer=Adam(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eww-QpXoUDRn",
        "outputId": "d1c47333-1b4d-42e3-c4cb-859df4b2c9d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model5.fit(train_data,\n",
        "                    epochs = 100,steps_per_epoch=5712//32,\n",
        "                    validation_data=valid_data,validation_steps= 1311//32,\n",
        "                    verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tfVAVUEUXrR",
        "outputId": "aef620d5-8755-4a27-b2b6-50a13dce8431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "178/178 [==============================] - 480s 3s/step - loss: 0.8272 - accuracy: 0.7011 - val_loss: 0.8367 - val_accuracy: 0.6977\n",
            "Epoch 2/100\n",
            "178/178 [==============================] - 123s 689ms/step - loss: 0.5440 - accuracy: 0.7991 - val_loss: 0.5025 - val_accuracy: 0.7977\n",
            "Epoch 3/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.4138 - accuracy: 0.8465 - val_loss: 1.6987 - val_accuracy: 0.5961\n",
            "Epoch 4/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.3561 - accuracy: 0.8678 - val_loss: 2.3718 - val_accuracy: 0.4117\n",
            "Epoch 5/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.2902 - accuracy: 0.8951 - val_loss: 0.7624 - val_accuracy: 0.7641\n",
            "Epoch 6/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.2418 - accuracy: 0.9123 - val_loss: 0.3317 - val_accuracy: 0.8852\n",
            "Epoch 7/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.1949 - accuracy: 0.9326 - val_loss: 0.3514 - val_accuracy: 0.8703\n",
            "Epoch 8/100\n",
            "178/178 [==============================] - 123s 689ms/step - loss: 0.1842 - accuracy: 0.9384 - val_loss: 0.2027 - val_accuracy: 0.9250\n",
            "Epoch 9/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.1319 - accuracy: 0.9519 - val_loss: 0.7878 - val_accuracy: 0.7492\n",
            "Epoch 10/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.1245 - accuracy: 0.9574 - val_loss: 0.2328 - val_accuracy: 0.9039\n",
            "Epoch 11/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.1142 - accuracy: 0.9590 - val_loss: 0.8908 - val_accuracy: 0.7656\n",
            "Epoch 12/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.1249 - accuracy: 0.9579 - val_loss: 0.3484 - val_accuracy: 0.8648\n",
            "Epoch 13/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0876 - accuracy: 0.9695 - val_loss: 0.6326 - val_accuracy: 0.8594\n",
            "Epoch 14/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.1069 - accuracy: 0.9681 - val_loss: 0.1097 - val_accuracy: 0.9617\n",
            "Epoch 15/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0697 - accuracy: 0.9736 - val_loss: 0.2296 - val_accuracy: 0.9203\n",
            "Epoch 16/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0796 - accuracy: 0.9708 - val_loss: 0.2553 - val_accuracy: 0.9117\n",
            "Epoch 17/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.2699 - val_accuracy: 0.9039\n",
            "Epoch 18/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0787 - accuracy: 0.9754 - val_loss: 0.3680 - val_accuracy: 0.8719\n",
            "Epoch 19/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0701 - accuracy: 0.9780 - val_loss: 0.1152 - val_accuracy: 0.9625\n",
            "Epoch 20/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.0429 - accuracy: 0.9864 - val_loss: 1.0922 - val_accuracy: 0.7578\n",
            "Epoch 21/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 0.1597 - val_accuracy: 0.9500\n",
            "Epoch 22/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0368 - accuracy: 0.9852 - val_loss: 0.0588 - val_accuracy: 0.9836\n",
            "Epoch 23/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0309 - accuracy: 0.9898 - val_loss: 0.4348 - val_accuracy: 0.8969\n",
            "Epoch 24/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 0.0903 - val_accuracy: 0.9672\n",
            "Epoch 25/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 0.0672 - val_accuracy: 0.9766\n",
            "Epoch 26/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.1103 - val_accuracy: 0.9578\n",
            "Epoch 27/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0280 - accuracy: 0.9880 - val_loss: 0.0310 - val_accuracy: 0.9891\n",
            "Epoch 28/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.0342 - accuracy: 0.9871 - val_loss: 0.0642 - val_accuracy: 0.9805\n",
            "Epoch 29/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.0444 - val_accuracy: 0.9867\n",
            "Epoch 30/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.0820 - val_accuracy: 0.9773\n",
            "Epoch 31/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.0540 - accuracy: 0.9859 - val_loss: 0.3156 - val_accuracy: 0.9211\n",
            "Epoch 32/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0282 - accuracy: 0.9891 - val_loss: 0.0430 - val_accuracy: 0.9875\n",
            "Epoch 33/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0803 - val_accuracy: 0.9703\n",
            "Epoch 34/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.5688 - val_accuracy: 0.8719\n",
            "Epoch 35/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0347 - val_accuracy: 0.9891\n",
            "Epoch 36/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.0103 - accuracy: 0.9960 - val_loss: 0.1464 - val_accuracy: 0.9641\n",
            "Epoch 37/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0188 - accuracy: 0.9923 - val_loss: 0.2565 - val_accuracy: 0.9195\n",
            "Epoch 38/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.0394 - val_accuracy: 0.9891\n",
            "Epoch 39/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.0436 - val_accuracy: 0.9867\n",
            "Epoch 40/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 0.1357 - val_accuracy: 0.9523\n",
            "Epoch 41/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0344 - accuracy: 0.9879 - val_loss: 0.0818 - val_accuracy: 0.9711\n",
            "Epoch 42/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.0495 - val_accuracy: 0.9867\n",
            "Epoch 43/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1103 - val_accuracy: 0.9711\n",
            "Epoch 44/100\n",
            "178/178 [==============================] - 124s 694ms/step - loss: 0.0246 - accuracy: 0.9907 - val_loss: 0.3366 - val_accuracy: 0.9273\n",
            "Epoch 45/100\n",
            "178/178 [==============================] - 123s 690ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.2859 - val_accuracy: 0.9297\n",
            "Epoch 46/100\n",
            "178/178 [==============================] - 123s 690ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0889 - val_accuracy: 0.9664\n",
            "Epoch 47/100\n",
            "178/178 [==============================] - 123s 691ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.1732 - val_accuracy: 0.9477\n",
            "Epoch 48/100\n",
            "178/178 [==============================] - 123s 689ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.4468 - val_accuracy: 0.8641\n",
            "Epoch 49/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.0304 - accuracy: 0.9910 - val_loss: 0.0702 - val_accuracy: 0.9844\n",
            "Epoch 50/100\n",
            "178/178 [==============================] - 123s 689ms/step - loss: 0.0268 - accuracy: 0.9956 - val_loss: 5.5289 - val_accuracy: 0.3320\n",
            "Epoch 51/100\n",
            "178/178 [==============================] - 124s 696ms/step - loss: 0.0615 - accuracy: 0.9868 - val_loss: 0.2271 - val_accuracy: 0.9516\n",
            "Epoch 52/100\n",
            "178/178 [==============================] - 124s 694ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0324 - val_accuracy: 0.9922\n",
            "Epoch 53/100\n",
            "178/178 [==============================] - 124s 695ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.1038 - val_accuracy: 0.9711\n",
            "Epoch 54/100\n",
            "178/178 [==============================] - 124s 694ms/step - loss: 0.0244 - accuracy: 0.9942 - val_loss: 0.0663 - val_accuracy: 0.9820\n",
            "Epoch 55/100\n",
            "178/178 [==============================] - 124s 694ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0429 - val_accuracy: 0.9852\n",
            "Epoch 56/100\n",
            "178/178 [==============================] - 124s 697ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.0682 - val_accuracy: 0.9812\n",
            "Epoch 57/100\n",
            "178/178 [==============================] - 123s 691ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0540 - val_accuracy: 0.9836\n",
            "Epoch 58/100\n",
            "178/178 [==============================] - 123s 689ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0266 - val_accuracy: 0.9961\n",
            "Epoch 59/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.4003 - val_accuracy: 0.9070\n",
            "Epoch 60/100\n",
            "178/178 [==============================] - 123s 691ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.1120 - val_accuracy: 0.9672\n",
            "Epoch 61/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0371 - val_accuracy: 0.9883\n",
            "Epoch 62/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 0.1899 - val_accuracy: 0.9469\n",
            "Epoch 63/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0650 - val_accuracy: 0.9805\n",
            "Epoch 64/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0328 - val_accuracy: 0.9898\n",
            "Epoch 65/100\n",
            "178/178 [==============================] - 123s 688ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
            "Epoch 66/100\n",
            "178/178 [==============================] - 123s 690ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0511 - val_accuracy: 0.9883\n",
            "Epoch 67/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0498 - val_accuracy: 0.9828\n",
            "Epoch 68/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.0350 - val_accuracy: 0.9914\n",
            "Epoch 69/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0400 - val_accuracy: 0.9891\n",
            "Epoch 70/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.0362 - val_accuracy: 0.9875\n",
            "Epoch 71/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.0370 - val_accuracy: 0.9891\n",
            "Epoch 72/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0565 - val_accuracy: 0.9883\n",
            "Epoch 73/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0275 - val_accuracy: 0.9922\n",
            "Epoch 74/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0712 - val_accuracy: 0.9789\n",
            "Epoch 75/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.0382 - val_accuracy: 0.9875\n",
            "Epoch 76/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0271 - val_accuracy: 0.9937\n",
            "Epoch 77/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 1.1772 - val_accuracy: 0.7992\n",
            "Epoch 78/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.0377 - val_accuracy: 0.9914\n",
            "Epoch 79/100\n",
            "178/178 [==============================] - 122s 684ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0966 - val_accuracy: 0.9727\n",
            "Epoch 80/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0180 - accuracy: 0.9933 - val_loss: 0.1010 - val_accuracy: 0.9719\n",
            "Epoch 81/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0304 - accuracy: 0.9926 - val_loss: 0.0295 - val_accuracy: 0.9891\n",
            "Epoch 82/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.1649 - val_accuracy: 0.9508\n",
            "Epoch 83/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1007 - val_accuracy: 0.9688\n",
            "Epoch 84/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.1231 - val_accuracy: 0.9711\n",
            "Epoch 85/100\n",
            "178/178 [==============================] - 122s 687ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0418 - val_accuracy: 0.9836\n",
            "Epoch 86/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0297 - val_accuracy: 0.9922\n",
            "Epoch 87/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0114 - val_accuracy: 0.9953\n",
            "Epoch 88/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.0373 - val_accuracy: 0.9914\n",
            "Epoch 89/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0251 - val_accuracy: 0.9937\n",
            "Epoch 90/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0510 - val_accuracy: 0.9836\n",
            "Epoch 91/100\n",
            "178/178 [==============================] - 123s 687ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.0356 - val_accuracy: 0.9906\n",
            "Epoch 92/100\n",
            "178/178 [==============================] - 122s 685ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0261 - val_accuracy: 0.9953\n",
            "Epoch 93/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.1428 - val_accuracy: 0.9617\n",
            "Epoch 94/100\n",
            "178/178 [==============================] - 122s 686ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0801 - val_accuracy: 0.9789\n",
            "Epoch 95/100\n",
            " 63/178 [=========>....................] - ETA: 1:11 - loss: 0.0144 - accuracy: 0.9945"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3ldgiR3bpXLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fHIHDCJ4xjd3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}